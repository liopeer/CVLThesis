%% ----------------------------------------------------------------------------
% BIWI SA/MA thesis template
%
% Created 09/29/2006 by Andreas Ess
% Extended 13/02/2009 by Jan Lesniak - jlesniak@vision.ee.ethz.ch
%% ----------------------------------------------------------------------------


\chapter{Introduction}
\section{Background \& Relevance}
MRI (magnetic resonance imaging) is a medical imaging modality that allows acquiring slices of the body, which is an invaluable non-invasive procedure in medical diagnostics. In contrast to the widely used CT (computed tomography) it does not rely on ionizing radiation, which is harmful to the cells in large doses, and offers much better soft tissue contrast. As an additional benefit, acquisition protocols are highly flexible and often allow to tuning the contrast to tissues of interest. The biggest difficulty with MRI scans are the long acquisition times that require patients to lay still for extended amounts of time, which is especially difficult for children and intellectually disabled patients. Additionally, long acquisition times make scans more expensive and available to a smaller number of patients. A significant part of MRI-related research is therefore A speedup, without a drop in image quality, can be achieved by the use of several acquisition coils~\autocite{sodickson1997smash,pruessmann1999sense,griswold2002grappa} or by undersampling the acquisition space, which, in the case of MRI, is the space of spatial frequencies. This space corresponds to the 2D Fourier transform of the image space and is usually termed \textit{k-space}, relating to the variable $k$, which is usually assigned to the spatial frequency. Undersampling k-space poses a challenging inverse problem that can be solved well by compressed sensing techniques~\autocite{donoho2006compressedsensing,candes2005stable} for small accelerations (undersampling factors), but usually requires stronger priors for higher accelerations. Since generative machine learning is concerned with learning data distributions it offers a possibility for incorporating such strong priors into inverse problems and generative machine learning for images has made huge progress in the last few years, thanks to the incorporation of neural networks. Visionary works in the domains of variational autoencoders (VAEs), generative adversarial networks (GANs) and diffusion denoising probabilistic models (DDPMs) have opened the door to a variety of models that can learn complicated image distributions and produce samples of photo-realistic quality.~\autocite{kingma2013autoencoding,goodfellow2014generative,sohldickstein2015deep,ho2020denoising}

\section{Focus of this Work}
DDPMs have recently emerged as the most powerful model for modeling image distributions and therefore they are the model used in this work. The focus is to train DDPMs on large amounts of high-quality MRI data from various acquisition protocols and to then use this prior for reconstruction of undersampled k-space. The advantage of this approach is that the type of undersampling does not need to be known at training time, and that a single model could also be used for a variety of other image reconstruction tasks. This means that the model needs to be conditioned on the task of reconstructing undersampled MRI post-training. Thanks to the high interpretability of DDPMs, they allow for several different approaches to this conditioning, which are explored in this work. A further focus lies on the exploration of sampling techniques that might give better reconstruction quality by making use of higher computational resources.
\section{Thesis Organization}
In the first part of the thesis, the theoretical framework behind DDPMs is established and related work is introduced, that successfully managed to condition unconditionally trained DDPMs. In the second part, the introduced conditioning methods are adapted to fit the task of reconstructing undersampled MRI and the used model architectures, training protocols and datasets are introduced. The third part shows the experimental results from model training and compares the performance between the different conditioning methods, by evaluating them over different accelerations and sampling strategies.